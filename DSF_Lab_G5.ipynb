{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Exercise [30 Marks]\n",
    "\n",
    "### <font color='red'>Deadline: 15<sup>th</sup> September 2024 (Sunday), 11.59pm.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "- Download and rename this notebook according to your group number, e.g.: `LabEx_GXX.ipynb`.\n",
    "- Fill in all group members' details in the following Markdown cell.\n",
    "- Fill in every group member's contribution in percentage, with the total 100%. All the members MUST AGREE to the percentages before submission. For example, the group members can agree to give 0% contribution to the sleeping group member. \n",
    "- Not all group members in the same group will get the same mark. Your mark is depending on your contribution to the group work.\n",
    "- Complete all the questions. Fill in your ANSWERS IN THIS NOTEBOOK. You can add new cells as needed. Do not change/delete provided cells.\n",
    "- Submit this lab exercise to EbWise in <b> .ipynb file </b>. Name your submission file as `LabEx_GXX.ipynb`.\n",
    "\n",
    "## Penalties\n",
    "- For submission that does not conform to <i> Submission Instructions </i>, <b> 5 marks will be deducted </b>. \n",
    "- For submission <i> after the Deadline </i>, late submission penalty is applied with a deduction of <b> 5 marks per hour </b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group##\n",
    "\n",
    "**Tutorial section: TT1L**\n",
    "\n",
    "|   |  Student ID  |           Student Nae             | Contribution | \n",
    "|--:|:-------------|:----------------------------------|-------------:|\n",
    "| 1 |  1191103320  | Ahmad Zubir Bin Zainudin          |      25%     | \n",
    "| 2 |  1221302587  | NUR FATIN NABILAH BINTI MD. IRZAN |      25%     | \n",
    "| 3 |  1211307291  | NUR AINAHUSNA BINTI MOHD NASIR    |      25%     | \n",
    "| 4 |  1221305140  | ANIS NUR HANANI BINTI AZHAR       |      25%     | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1 [10 mark]\n",
    "The dataset can be downloaded from https://archive.ics.uci.edu/dataset/1/abalone\n",
    "\n",
    "### Complete the tasks below:\n",
    "1. Import and prepare the `abalone` dataset.\n",
    "1. Conduct a k-means cluster analysis. Displays the parameters of the fitted model.\n",
    "1. Visualize the clusters and the cluster centers at the same plot. Use `Diameter` and `WholeWeight` as your axes.\n",
    "1. Visualize the `Type` of Abalone in the original dataset. Use `Diameter` and `WholeWeight` as your axes.\n",
    "1. State your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names\n",
    "column_names = ['Sex', 'LongestShell', 'Diameter', 'Height', 'WholeWeight', \n",
    "                 'ShuckedWeight', 'VisceraWeight', 'ShellWeight', 'Rings']\n",
    "\n",
    "# Load the dataset, skipping the first row if it contains headers\n",
    "url = \"abalone.data\"\n",
    "abalone_data = pd.read_csv(url, header=None, names=column_names, skiprows=1)\n",
    "\n",
    "# Convert 'Sex' categorical variable into numerical using one-hot encoding\n",
    "abalone_data = pd.get_dummies(abalone_data, columns=['Sex'])\n",
    "\n",
    "# Convert all columns to numeric (if there are any non-numeric values, they'll be converted to NaN)\n",
    "abalone_data = abalone_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values (if any)\n",
    "abalone_data.dropna(inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(abalone_data.head())\n",
    "\n",
    "# Select relevant features\n",
    "features = ['Diameter', 'WholeWeight']\n",
    "X = abalone_data[features]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets up the KMeans Model\n",
    "#### Display the parameters of the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and fit the KMeans model\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Display the parameters of the fitted model\n",
    "print(\"KMeans Model Parameters:\")\n",
    "print(f\"Number of clusters: {kmeans.n_clusters}\")\n",
    "print(f\"Cluster centers (scaled): \\n{kmeans.cluster_centers_}\")\n",
    "print(f\"Inertia: {kmeans.inertia_}\")\n",
    "\n",
    "# Get cluster labels\n",
    "abalone_data['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Clusters with the Cluster Centers \n",
    "\n",
    "Focuses on clustering results and shows how the data is segmented into clusters and where the cluster centers are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the data\n",
    "abalone_data['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Inverse transform the scaled cluster centers for plotting\n",
    "centers_unscaled = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "\n",
    "# Visualize the clusters and the cluster centers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Diameter', y='WholeWeight', hue='Cluster', data=abalone_data, palette='viridis', alpha=0.6, marker='o')\n",
    "plt.scatter(centers_unscaled[:, 0], \n",
    "            centers_unscaled[:, 1], \n",
    "            s=300, c='red', marker='X', label='Centroids')\n",
    "plt.title('Clusters and Cluster Centers')\n",
    "plt.xlabel('Diameter')\n",
    "plt.ylabel('WholeWeight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Dataset according to the `Type` of Abalone \n",
    "\n",
    "Focuses on the original type of abalone and shows how different types are distributed across the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the 'Sex' column from one-hot encoding\n",
    "abalone_data['Sex'] = abalone_data[['Sex_M', 'Sex_F', 'Sex_I']].idxmax(axis=1).map({\n",
    "    'Sex_M': 'M',\n",
    "    'Sex_F': 'F',\n",
    "    'Sex_I': 'I'\n",
    "})\n",
    "\n",
    "# Now, visualize the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Diameter', y='WholeWeight', hue='Sex', data=abalone_data, palette='Set1')\n",
    "plt.title('Abalone Dataset by Sex')\n",
    "plt.xlabel('Diameter')\n",
    "plt.ylabel('WholeWeight')\n",
    "plt.legend(title='Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation: \n",
    "- The abalone dataset was cleaned and processed, including encoding the Sex variable and standardizing features.\n",
    "\n",
    "---------------------------\n",
    "\n",
    "Number of clusters: 3\n",
    "\n",
    "Cluster centers (scaled):\n",
    "\n",
    "- Cluster 0: [-1.38, -1.19]  \n",
    "\n",
    "- Cluster 1: [1.02, 1.16]\n",
    "\n",
    "- Cluster 2: [0.05, -0.17]\n",
    "\n",
    "- Inertia: 1612.41\n",
    "\n",
    "These centers show the average Diameter and WholeWeight for each cluster.\n",
    "\n",
    "---------------------------\n",
    "\n",
    "Cluster Visualization: Clusters were plotted showing distinct groups of abalones based on size.\n",
    "\n",
    "Type Visualization: Plotting by Sex shows that Diameter and WholeWeight do not clearly separate abalones by sex.\n",
    "\n",
    "---------------------------\n",
    "\n",
    "Findings:\n",
    "\n",
    "- K-means clusters reveal size-based groups but do not effectively differentiate abalones by sex.\n",
    "- Size-based clustering is clear, but sex classification requires additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 [20 mark]\n",
    "For this question, we will use the \"Breast Cancer Wisconsin (Original) Data Set,\" which can be found at [https://j.mp/2NsaIlc](https://j.mp/2NsaIlc). \n",
    "\n",
    "### Complete the tasks below:\n",
    "1. Import the Breast Cancer datasets from 'breast-cancer.data'. The attribute information can be found in 'breast-cancer.names'.\n",
    "1. Clean and prepare the Breast Cancer datasets, save it as  a CSV file named 'BreasrCancer.csv'.\n",
    "1. Feature engineering: discuss your approach.\n",
    "1. Train a kNN model based on the dataset to classify the 'class' (benign or malignant) based on the given attributes.\n",
    "1. Optimize your kNN model and display the optimum model. \n",
    "1. Plot the accuracy of the model parameters. \n",
    "1. Graph the confusion matrix and calculate the overall accuracy of the model on the testing data.\n",
    "1. Discussion: observation/finding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Dataset from file\n",
    "\n",
    "Start by importing necessary libraries and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "column_names = [\n",
    "    'id', 'clump_thickness', 'uniformity_of_cell_size', 'uniformity_of_cell_shape',\n",
    "    'marginal_adhesion', 'single_epithelial_cell_size', 'bare_nuclei', \n",
    "    'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class'\n",
    "]\n",
    "data = pd.read_csv('breast-cancer.data', names=column_names, na_values='?')\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Save the Dataset as CSV\n",
    "\n",
    "Clean the dataset by handling missing values, converting categorical attributes, and saving it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert categorical attributes to numeric if necessary\n",
    "# Mapping: 2 -> 0 (benign), 4 -> 1 (malignant)\n",
    "data['class'] = data['class'].map({2: 0, 4: 1})\n",
    "\n",
    "# Save cleaned dataset\n",
    "data.to_csv('BreastCancer.csv', index=False)\n",
    "\n",
    "# Verify the cleaned data\n",
    "data_cleaned = pd.read_csv('BreastCancer.csv')\n",
    "print(\"Cleaned Data:\")\n",
    "print(data_cleaned.head())\n",
    "print(\"Missing values in 'class' column:\")\n",
    "print(data_cleaned['class'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop(['id', 'class'], axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "#### Discuss your approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN: TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the kNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the kNN Model and Display the optimum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'n_neighbors': range(1, 21)}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Optimal parameters\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Optimal number of neighbors: {best_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Accuracy for Various Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for each parameter value\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='param_n_neighbors', y='mean_test_score', data=results)\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('kNN Accuracy vs Number of Neighbors')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph the confusion matrix and calculate the overall accuracy of the model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plagiarism\n",
    "It is fine to seek help from friends or from online resources when you do the assignment, However,\n",
    "seeking help should not go overboard, to the point of getting (or even paying) someone to\n",
    "complete the assignment partly or fully for you, copying from online resources without\n",
    "understanding, or doing any means with the intention to cheat. \n",
    "\n",
    "For this assignment, plagiarism\n",
    "means the following:\n",
    "(a) Turning in a work that, from the examiner’s point of view, you do not sufficiently understand.\n",
    "(b) Turning in someone else’s work (whether partly or fully) as your own.\n",
    "(c) To use another’s work (whether partly or fully) without crediting the source.\n",
    "(d) Any means of cheating.\n",
    "\n",
    "**Plagiarism is a serious offence.**\n",
    "\n",
    "**We will give ZERO (0) marks to students who plagiarize AND to students who intentionally or\n",
    "unintentionally help other students to plagiarize by giving all or some of their code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Submit\n",
    "All submission via EbWise/OneDrive according to your tutorial section (check with your tutor where to submit).\n",
    "\n",
    "**Name your Lab Exercise file accordingly.** \\\n",
    "Ensure your `.ipynb` file is properly named. Double check all group members' ID, name, and contribution before submission. \n",
    "\n",
    "### <font color='red'>Deadline: 15<sup>th</sup> September 2024 (Sunday), 11.59pm.</font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "tHmgx",
   "launcher_item_id": "Um6Bz",
   "part_id": "OQsnr"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
